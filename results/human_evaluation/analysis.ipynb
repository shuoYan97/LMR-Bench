{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e50415d-20a3-4afc-9129-500d08e5e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# â€”â€” 1. åŠ è½½å¹¶åˆå¹¶åŸå§‹ JSON åˆ—è¡¨ â€”â€”\n",
    "with open('kaiyu.json', 'r', encoding='utf-8') as f:\n",
    "    kaiyu = json.load(f)\n",
    "with open('shuo.json', 'r', encoding='utf-8') as f:\n",
    "    shuo = json.load(f)\n",
    "with open('daoyang.json', 'r', encoding='utf-8') as f:\n",
    "    daoyang = json.load(f)\n",
    "with open('ziming.json', 'r', encoding='utf-8') as f:\n",
    "    ziming = json.load(f)\n",
    "\n",
    "# å¯¹ ziming ä¸­çš„ human_judge_result +1\n",
    "for rec in ziming:\n",
    "    rec['human_judge_result'] += 1\n",
    "\n",
    "# åˆå¹¶æ‰€æœ‰è®°å½•ï¼Œä¿æŒå¯¹åŸåˆ—è¡¨ä¸­ dict çš„å¼•ç”¨\n",
    "human_evaluation_data = kaiyu + shuo + daoyang + ziming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1acfc99-50cc-47df-b692-bed053e744c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n"
     ]
    }
   ],
   "source": [
    "print(len(human_evaluation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb368285-d029-47d9-a8f2-f5f9d0c14fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…±æœ‰ 28 æ¡è®°å½• human_judge_result=1 ä¸” paper_index åœ¨ [1, 2, 3, 7, 8, 9, 11, 30, 31] ä¸­ï¼Œéœ€è¦å¤„ç†ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# â€”â€” 2. å®šä¹‰ outputs åŸºè·¯å¾„ï¼Œå¾€ä¸Šä¸€çº§ç›®å½• â€”â€”â€”\n",
    "base_outputs = Path.cwd().parent / \"outputs\"\n",
    "\n",
    "\n",
    "# â€”â€” 3. åªä¿ç•™ human_judge_result==1 ä¸” paper_index åœ¨æŒ‡å®šåˆ—è¡¨ä¸­çš„è®°å½• â€”â€”\n",
    "target_papers = [1, 2, 3, 7, 8, 9, 11, 30, 31]\n",
    "records_to_update = [\n",
    "    rec for rec in human_evaluation_data\n",
    "    if rec.get('human_judge_result') == 1 and rec.get('paper_index') in target_papers\n",
    "]\n",
    "print(f\"å…±æœ‰ {len(records_to_update)} æ¡è®°å½• human_judge_result=1 ä¸” paper_index åœ¨ {target_papers} ä¸­ï¼Œéœ€è¦å¤„ç†ã€‚\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a32e0-a3b5-4875-8302-23a099bcaf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/28] æ³¨é‡Šè€…=kaiyu, ä»£ç†=no_agent, æ¨¡å‹=gpt4.1, è®ºæ–‡=2, å‡½æ•°ç´¢å¼•=0\n",
      "Original comment: \"LLM using the other class function not used in gold answer, and the loss function didn't implement the forward, therefore the loss will return None\"\n",
      "\n",
      "Instruction:\n",
      "Implement the forward function of calulating the Hyperbolic Loss in src/hierarchy_transformers/losses/hit_loss.py based on paper.pdf.\n",
      "\n",
      "Goal Function: forward\n",
      "Class Name: HierarchyTransformerLoss\n",
      "\n",
      "--- src/hierarchy_transformers/losses/hit_loss.py å†…å®¹ ---\n",
      "from __future__ import annotations\n",
      "import logging\n",
      "from collections.abc import Iterable\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from geoopt.manifolds import PoincareBall\n",
      "from hierarchy_transformers.models import HierarchyTransformer\n",
      "from hierarchy_transformers.utils import format_citation\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "class HierarchyTransformerLoss(torch.nn.Module):\n",
      "    \"\"\"Hyperbolic loss that linearly combines hperbolic clustering loss and hyperbolic Centripetal loss and applies weights for joint optimisation.\"\"\"\n",
      "\n",
      "    def __init__(self, model: HierarchyTransformer, clustering_loss_weight: float=1.0, clustering_loss_margin: float=5.0, centripetal_loss_weight: float=1.0, centripetal_loss_margin: float=0.5):\n",
      "        super().__init__()\n",
      "        self.model = model\n",
      "        self.manifold = self.model.manifold\n",
      "        self.cluster_weight = clustering_loss_weight\n",
      "        self.centri_weight = centripetal_loss_weight\n",
      "        self.cluster_loss_margin = clustering_loss_margin\n",
      "        self.centri_loss_margin = centripetal_loss_margin\n",
      "\n",
      "    def forward(self, sentence_features: Iterable[dict[str, torch.Tensor]], labels: torch.Tensor):\n",
      "        \"\"\"Forward propagation that follows [`sentence_transformers.losses`](https://github.com/UKPLab/sentence-transformers/tree/master/sentence_transformers/losses).\"\"\"\n",
      "        reps = [self.model(sentence_feature)['sentence_embedding'] for sentence_feature in sentence_features]\n",
      "        assert len(reps) == 3\n",
      "        rep_anchor, rep_positive, rep_negative = reps\n",
      "        cluster_loss_fn = HyperbolicClusteringLoss(self.manifold, self.cluster_loss_margin)\n",
      "        cluster_loss = cluster_loss_fn(rep_anchor, rep_positive, rep_negative)\n",
      "        centri_loss_fn = HyperbolicCentripetalLoss(self.manifold, self.centri_loss_margin)\n",
      "        centri_loss = centri_loss_fn(rep_anchor, rep_positive, rep_negative)\n",
      "        combined_loss = 0.0\n",
      "        if self.cluster_weight > 0.0 and cluster_loss is not None:\n",
      "            combined_loss = combined_loss + self.cluster_weight * cluster_loss\n",
      "        if self.centri_weight > 0.0 and centri_loss is not None:\n",
      "            combined_loss = combined_loss + self.centri_weight * centri_loss\n",
      "        return {'loss': combined_loss, 'cluster_loss': cluster_loss, 'centri_loss': centri_loss}\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation('\\n            @article{he2024language,\\n              title={Language models as hierarchy encoders},\\n              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\\n              journal={arXiv preprint arXiv:2401.11374},\\n              year={2024}\\n            }\\n            ')\n",
      "\n",
      "class HyperbolicClusteringLoss(torch.nn.Module):\n",
      "    \"\"\"Hyperbolic loss that clusters entities in subsumptions.\n",
      "\n",
      "    Essentially, this loss is expected to achieve:\n",
      "\n",
      "    $$d(child, parent) < d(child, negative)$$\n",
      "\n",
      "    Inputs are presented in `(rep_anchor, rep_positive, rep_negative)`.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, manifold: PoincareBall, margin: float):\n",
      "        super().__init__()\n",
      "        self.manifold = manifold\n",
      "        self.margin = margin\n",
      "\n",
      "    def get_config_dict(self):\n",
      "        config = {'distance_metric': f'PoincareBall(c={self.manifold.c}).dist', 'margin': self.margin}\n",
      "        return config\n",
      "\n",
      "    def forward(self, rep_anchor: torch.Tensor, rep_positive: torch.Tensor, rep_negative: torch.Tensor):\n",
      "        pass\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation('\\n            @article{he2024language,\\n              title={Language models as hierarchy encoders},\\n              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\\n              journal={arXiv preprint arXiv:2401.11374},\\n              year={2024}\\n            }\\n            ')\n",
      "\n",
      "class HyperbolicCentripetalLoss(torch.nn.Module):\n",
      "    \"\"\"Hyperbolic loss that regulates the norms of child and parent entities.\n",
      "\n",
      "    Essentially, this loss is expected to achieve:\n",
      "\n",
      "    $$d(child, origin) > d(parent, origin)$$\n",
      "\n",
      "    Inputs are presented in `(rep_anchor, rep_positive, rep_negative)` but only `(rep_anchor, rep_positive)` pairs are involved in this loss.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, manifold: PoincareBall, margin: float):\n",
      "        super().__init__()\n",
      "        self.manifold = manifold\n",
      "        self.margin = margin\n",
      "\n",
      "    def get_config_dict(self):\n",
      "        config = {'distance_metric': f'PoincareBall(c={self.manifold.c}).dist0', 'margin': self.margin}\n",
      "        return config\n",
      "\n",
      "    def forward(self, rep_anchor: torch.Tensor, rep_positive: torch.Tensor, rep_negative: torch.Tensor):\n",
      "        pass\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation('\\n            @article{he2024language,\\n              title={Language models as hierarchy encoders},\\n              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\\n              journal={arXiv preprint arXiv:2401.11374},\\n              year={2024}\\n            }\\n            ')\n",
      "\n",
      "--- golden_files/hit_loss_golden.py å†…å®¹ ---\n",
      "# Copyright 2023 Yuan He\n",
      "\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "from __future__ import annotations\n",
      "\n",
      "import logging\n",
      "from collections.abc import Iterable\n",
      "\n",
      "import torch\n",
      "import torch.nn.functional as F\n",
      "from geoopt.manifolds import PoincareBall\n",
      "\n",
      "from hierarchy_transformers.models import HierarchyTransformer\n",
      "from hierarchy_transformers.utils import format_citation\n",
      "\n",
      "logger = logging.getLogger(__name__)\n",
      "\n",
      "\n",
      "class HierarchyTransformerLoss(torch.nn.Module):\n",
      "    \"\"\"Hyperbolic loss that linearly combines hperbolic clustering loss and hyperbolic Centripetal loss and applies weights for joint optimisation.\"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        model: HierarchyTransformer,\n",
      "        clustering_loss_weight: float = 1.0,\n",
      "        clustering_loss_margin: float = 5.0,\n",
      "        centripetal_loss_weight: float = 1.0,\n",
      "        centripetal_loss_margin: float = 0.5,\n",
      "    ):\n",
      "        super().__init__()\n",
      "\n",
      "        self.model = model\n",
      "        self.manifold = self.model.manifold\n",
      "        self.cluster_weight = clustering_loss_weight\n",
      "        self.centri_weight = centripetal_loss_weight\n",
      "        self.cluster_loss_margin = clustering_loss_margin\n",
      "        self.centri_loss_margin = centripetal_loss_margin\n",
      "\n",
      "    def forward(self, sentence_features: Iterable[dict[str, torch.Tensor]], labels: torch.Tensor):\n",
      "        \"\"\"Forward propagation that follows [`sentence_transformers.losses`](https://github.com/UKPLab/sentence-transformers/tree/master/sentence_transformers/losses).\"\"\"\n",
      "        reps = [self.model(sentence_feature)[\"sentence_embedding\"] for sentence_feature in sentence_features]\n",
      "        assert len(reps) == 3\n",
      "        rep_anchor, rep_positive, rep_negative = reps\n",
      "\n",
      "        # compute and combine hyperbolic clustering and centripetal losses\n",
      "\n",
      "        # cluster_loss = self.cluster_loss(rep_anchor, rep_positive, rep_negative)\n",
      "        distances_positive = self.manifold.dist(rep_anchor, rep_positive)\n",
      "        distances_negative = self.manifold.dist(rep_anchor, rep_negative)\n",
      "        cluster_triplet_loss = F.relu(distances_positive - distances_negative + self.cluster_loss_margin)\n",
      "        cluster_loss = cluster_triplet_loss.mean()\n",
      "\n",
      "        # centri_loss = self.centri_loss(rep_anchor, rep_positive, rep_negative)\n",
      "        rep_anchor_hyper_norms = self.manifold.dist0(rep_anchor)\n",
      "        rep_positive_hyper_norms = self.manifold.dist0(rep_positive)\n",
      "        # child further than parent w.r.t. origin\n",
      "        centri_triplet_loss = F.relu(self.centri_loss_margin + rep_positive_hyper_norms - rep_anchor_hyper_norms)\n",
      "        centri_loss = centri_triplet_loss.mean()\n",
      "\n",
      "        combined_loss = self.cluster_weight * cluster_loss + self.centri_weight * centri_loss\n",
      "\n",
      "        return {\n",
      "            \"loss\": combined_loss,\n",
      "            \"cluster_loss\": cluster_loss,\n",
      "            \"centri_loss\": centri_loss,\n",
      "        }\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation(\n",
      "            \"\"\"\n",
      "            @article{he2024language,\n",
      "              title={Language models as hierarchy encoders},\n",
      "              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\n",
      "              journal={arXiv preprint arXiv:2401.11374},\n",
      "              year={2024}\n",
      "            }\n",
      "            \"\"\"\n",
      "        )\n",
      "\n",
      "\n",
      "class HyperbolicClusteringLoss(torch.nn.Module):\n",
      "    r\"\"\"Hyperbolic loss that clusters entities in subsumptions.\n",
      "\n",
      "    Essentially, this loss is expected to achieve:\n",
      "\n",
      "    $$d(child, parent) < d(child, negative)$$\n",
      "\n",
      "    Inputs are presented in `(rep_anchor, rep_positive, rep_negative)`.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, manifold: PoincareBall, margin: float):\n",
      "        super().__init__()\n",
      "        self.manifold = manifold\n",
      "        self.margin = margin\n",
      "\n",
      "    def get_config_dict(self):\n",
      "        config = {\n",
      "            \"distance_metric\": f\"PoincareBall(c={self.manifold.c}).dist\",\n",
      "            \"margin\": self.margin,\n",
      "        }\n",
      "        return config\n",
      "\n",
      "    def forward(self, rep_anchor: torch.Tensor, rep_positive: torch.Tensor, rep_negative: torch.Tensor):\n",
      "        pass\n",
      "\n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation(\n",
      "            \"\"\"\n",
      "            @article{he2024language,\n",
      "              title={Language models as hierarchy encoders},\n",
      "              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\n",
      "              journal={arXiv preprint arXiv:2401.11374},\n",
      "              year={2024}\n",
      "            }\n",
      "            \"\"\"\n",
      "        )\n",
      "\n",
      "\n",
      "class HyperbolicCentripetalLoss(torch.nn.Module):\n",
      "    r\"\"\"Hyperbolic loss that regulates the norms of child and parent entities.\n",
      "\n",
      "    Essentially, this loss is expected to achieve:\n",
      "\n",
      "    $$d(child, origin) > d(parent, origin)$$\n",
      "\n",
      "    Inputs are presented in `(rep_anchor, rep_positive, rep_negative)` but only `(rep_anchor, rep_positive)` pairs are involved in this loss.\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, manifold: PoincareBall, margin: float):\n",
      "        super().__init__()\n",
      "        self.manifold = manifold\n",
      "        self.margin = margin\n",
      "\n",
      "    def get_config_dict(self):\n",
      "        config = {\n",
      "            \"distance_metric\": f\"PoincareBall(c={self.manifold.c}).dist0\",\n",
      "            \"margin\": self.margin,\n",
      "        }\n",
      "        return config\n",
      "\n",
      "    def forward(self, rep_anchor: torch.Tensor, rep_positive: torch.Tensor, rep_negative: torch.Tensor):\n",
      "        pass\n",
      " \n",
      "    @property\n",
      "    def citation(self) -> str:\n",
      "        return format_citation(\n",
      "            \"\"\"\n",
      "            @article{he2024language,\n",
      "              title={Language models as hierarchy encoders},\n",
      "              author={He, Yuan and Yuan, Zhangdie and Chen, Jiaoyan and Horrocks, Ian},\n",
      "              journal={arXiv preprint arXiv:2401.11374},\n",
      "              year={2024}\n",
      "            }\n",
      "            \"\"\"\n",
      "        )\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, record in enumerate(records_to_update, 1):\n",
    "    annotator     = record['annotator']\n",
    "    agent_type    = record['agent_type']\n",
    "    model_name    = record['model_name']\n",
    "    paper_index   = record['paper_index']\n",
    "    function_index= record['function_index']\n",
    "    original_comment = record.get('comment', '')\n",
    "    \n",
    "    # é€‰æ‹© BaseAgent æˆ– OpenHands ç›®å½•\n",
    "    agent_dir = \"BaseAgent\" if agent_type == \"no_agent\" else \"OpenHands\"\n",
    "    model_dir = base_outputs / agent_dir / model_name\n",
    "    \n",
    "    # æŸ¥æ‰¾ä»¥ \"{paper_index}-\" å¼€å¤´çš„è®ºæ–‡æ–‡ä»¶å¤¹\n",
    "    paper_folders = [p for p in model_dir.iterdir() \n",
    "                     if p.is_dir() and p.name.startswith(f\"{paper_index}-\")]\n",
    "    if not paper_folders:\n",
    "        print(f\"âŒ æœªæ‰¾åˆ°è®ºæ–‡ {paper_index} æ–‡ä»¶å¤¹: {model_dir}\")\n",
    "        continue\n",
    "    paper_folder = sorted(paper_folders)[0]\n",
    "    \n",
    "    # è¯»å– info.json\n",
    "    info = json.loads((paper_folder / \"info.json\").read_text(encoding='utf-8'))\n",
    "    repo_folder_name = info['repo_folder_name']\n",
    "    impls = info['implementations']\n",
    "    \n",
    "    # è·å–æŒ‡å®šå®ç°é¡¹\n",
    "    impl = impls[function_index]\n",
    "    instruction    = impl.get('instruction', '')\n",
    "    goal_file_rel  = impl.get('goal_file', '')\n",
    "    goal_function  = impl.get('goal_function', '')\n",
    "    class_name     = impl.get('class_name', '')\n",
    "    golden_file_rel= impl.get('golden_file', '')\n",
    "    \n",
    "    # â€”â€” æ‰“å°å…ƒä¿¡æ¯å’Œæ–‡ä»¶å†…å®¹ â€”â€”\n",
    "    print(f\"\\n[{idx}/{len(records_to_update)}] æ³¨é‡Šè€…={annotator}, ä»£ç†={agent_type}, æ¨¡å‹={model_name}, \"\n",
    "          f\"è®ºæ–‡={paper_index}, å‡½æ•°ç´¢å¼•={function_index}\")\n",
    "    print(f\"Original comment: {original_comment!r}\\n\")\n",
    "\n",
    "    print(f\"Instruction:\\n{instruction}\\n\")\n",
    "    print(f\"Goal Function: {goal_function}\")\n",
    "    print(f\"Class Name: {class_name}\\n\")\n",
    "    \n",
    "    # goal_file\n",
    "    goal_path = paper_folder / repo_folder_name / goal_file_rel\n",
    "    if goal_path.exists():\n",
    "        print(f\"--- {goal_file_rel} å†…å®¹ ---\")\n",
    "        print(goal_path.read_text(encoding='utf-8'))\n",
    "    else:\n",
    "        print(f\"âŒ æœªæ‰¾åˆ° goal_file: {goal_path}\")\n",
    "    \n",
    "    # golden_file\n",
    "    golden_path = paper_folder / golden_file_rel\n",
    "    if golden_path.exists():\n",
    "        print(f\"\\n--- {golden_file_rel} å†…å®¹ ---\")\n",
    "        print(golden_path.read_text(encoding='utf-8'))\n",
    "    else:\n",
    "        print(f\"âŒ æœªæ‰¾åˆ° golden_file: {golden_path}\")\n",
    "    \n",
    "    # â€”â€” äº¤äº’å¼è¾“å…¥ comment â€”â€” \n",
    "    new_comment = input(\"\\nè¯·è¾“å…¥æ–°çš„ commentï¼ˆç•™ç©ºè·³è¿‡ï¼‰ï¼š\").strip()\n",
    "    if new_comment:\n",
    "        record['comment'] = new_comment\n",
    "        print(\"âœ… å·²æ›´æ–° commentã€‚\\n\")\n",
    "    else:\n",
    "        print(\"â­ï¸ è·³è¿‡ï¼Œä¸ä¿®æ”¹ commentã€‚\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2e76e-5664-4adc-b0e5-841b9ba4510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_map = {\n",
    "    'kaiyu': kaiyu,\n",
    "    'shuo': shuo,\n",
    "    'daoyang': daoyang,\n",
    "    'ziming': ziming,\n",
    "}\n",
    "for filename, data_list in file_map.items():\n",
    "    with open(f'{filename}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(data_list, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"ğŸ’¾ ä¿å­˜æ›´æ–°åˆ° {filename}.json\")\n",
    "\n",
    "print(\"\\nå…¨éƒ¨å¤„ç†å®Œæ¯•ã€‚\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
